---
title: "Introduction to Pattern Matching and Regular Expressions"
author: 
  - "Dr. Gilbert"
date: "`r format(Sys.Date(), '%B %d, %Y')`"
output: 
  html_document:
    theme: cerulean
---

```{r global-options, include=FALSE}
#knitr::opts_chunk$set(eval = FALSE)
library(tidyverse)
library(tidymodels)
library(tidytext)
library(patchwork)
library(kableExtra)
library(reticulate)
```

**Purpose:** In this notebook we'll continue to expand our ability to extract insights from text data using a pattern-matching tool called *regular expressions* or *regex*.

## The Big Idea

Often times when working with text, we know the structure of the token we are looking for, but we don't know the exact token. For example, we may be digging through listings of items for sale on a social media marketplace and we want to know the cost of each of those items. We know that we are looking for a dollar sign (\$) followed by some digits, but we don't know the exact price. This isn't so much a problem for humans reading through a handful of postings, but if we are trying to get a computer to do this, we need some way to describe to a computer what a typical "price" might look like. This is where *regular expressions* come in.

### Building regex

Before we move forward, unless you work with *regular expressions* quite often, its likely that you're going to find them quite mysterious and that you'll forget the syntax for matching things like digits. Here's a link to a [*regex cheat sheet*](https://cheatography.com/davechild/cheat-sheets/regular-expressions/) from Dave Child and a link to an [*interactive regex applet*](https://regexr.com/) so that you can check that your regular expressions are working as you intend for them to. 

Regular expressions are also something you might ask your favorite AI assistant for help with. For example, I asked `chatGPT`, "Hey chatGPT, can you help me write a regular expression that will match dollar values in a posting? In particular, these dollar values may have commas separating thousands or millions of dollars and could contain decimals for cents. Thank you!" -- ChatGPT returned with the following regular expression `\$\d{1,3}(?:,\d{3})*(?:\.\d{1,2})?`, which works as intended according to the regex applet from the previous paragraph.

### How Do We Implement and Use regex?

There are lots of specialty text processing packages in Python, including `{nltk}`, `{SpaCy}`, and others. We can accomplish quite a bit in Python using basic string functionality from `{pandas}` and regular expressions though. In particular, the following functions can be applied to columns of data frames.

+ `Counter()` can be used in conjunction with the `.most_common()` method to identify the most common words in a text column.
+ `str.contains()` will search a string for a pattern match using either fixed strings or regular expressions.
+ `str.extract()` will collect all components in a string which match a pattern.

There's lots we can do, and you'll find more use-cases as you continue to explore working with text.

Let's consider an example. I'll load [this dataset](https://raw.githubusercontent.com/agmath/agmath.github.io/master/data/classification/biden_tweets.csv) containing Joe Biden's tweets from 2007 to 2020 which was [posted to Kaggle](https://www.kaggle.com/datasets/rohanrao/joe-biden-tweets) by user Vopani in 2020. We can see the first few tweets below.

```{python} 
import pandas as pd

biden_tweets = pd.read_csv("https://raw.githubusercontent.com/agmath/agmath.github.io/master/data/classification/biden_tweets.csv")
```

```{r}
py$biden_tweets %>%
  select(-id, -url) %>%
  head() %>%
  kable() %>%
  kable_styling(bootstrap_options = c("hover", "striped"))
```

Perhaps we want to extract the first appearing hashtag from each of the tweets posted by `@JoeBiden`. We can see the first tweets containing hashtags, along with their extracted hashtag, below.

DONE TO HERE -- I'm not loving working with text in python

```{python}
biden_tweets["hashtags"] = biden_tweets["tweet"].str.extract(r"(#[A-Za-z\d-]+)")
biden_hashtags = biden_tweets.loc[biden_tweets["hashtags"].notnull(), ["tweet", "hashtags"]]
```

```{r}
py$biden_hashtags %>%
  head() %>%
  kable() %>%
  kable_styling(bootstrap_options = c("hover", "striped"))
```

Perhaps we wanted all of the hashtags appearing in each tweet. Below is one way to do that -- but I am sure that there is a more efficient way.

```{python}
biden_hashtags = pd.DataFrame(biden_tweets["tweet"].str.extractall(r"(#[A-Za-z\d-]+)"))

biden_hashtags["tweet_number"] = biden_hashtags.index.get_level_values(0) 

biden_hashtags.columns = ["hashtags", "tweet_number"]

biden_tweets["tweet_number"] = biden_tweets.index

biden_hashtags = biden_hashtags.merge(biden_tweets[["tweet_number", "tweet"]], how = "left", left_on = "tweet_number", right_on = "tweet_number")
```

```{r}
py$biden_hashtags %>%
  head() %>%
  kable() %>%
  kable_styling(bootstrap_options = c("hover", "striped"))
```

Your ability to extract insights from text programmatically is strongly enhanced by command of regular expressions. This tool allows you to perform targeted inquiries about the presence or absence of particular components of text. Regular expressions can also be a way to extract numerical or categorical features from text descriptions as long as you are reasonably confident that the way those features appear across responses follows a consistent pattern.

In terms of model construction, you may continue to use some of the `{sklearn}` steps from `sklearn.feature_extraction.text` submodule from the previous notebook to engineer new model features. You may also create custom feature engineering functions for your modeling `Pipelines()` but doing so is outside of my expertise. You can read more about [custom feature engineering steps here](https://www.andrewvillazon.com/custom-scikit-learn-transformers/), from Andrew Villazon.

***

## Summary

We'll do more with regular expressions in our next class meeting. For now, you've seen how to use regular expressions for pattern matching. We can use regular expressions to filter observations or to extract particular components from text.