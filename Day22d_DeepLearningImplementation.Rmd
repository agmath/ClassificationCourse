---
title: 'Deep Learning: Implementation'
output:
  html_document:
    theme: cerulean
    highlight: pygments
  pdf_document: default
---

**Purpose:** The previous two notebooks have discussed theoretical and foundational aspects of deep learning models. In particular, what types of architectures and activation functions exist (and, to a lesser extent, how do I choose one). In this notebook our goal will be to actually build, assess, and utilize a deep learning network for image classification.

## Data and Modeling

Since you set up TensorFlow in an earlier notebook, let's load the `{tidyverse}`, `{tensorflow}`, `{keras}`, and `{reticulate}` libraries and get some data. We'll use the Fashion MNIST data set. You can learn more about that data set from [its official repository here](https://github.com/zalandoresearch/fashion-mnist).

```{r}
library(tidyverse)
library(tensorflow)
library(keras)
library(reticulate)
use_virtualenv("r-reticulate")

c(c(x_train, y_train), c(x_test, y_test)) %<-% keras::dataset_fashion_mnist()

x_train <- x_train/255
x_test <- x_test/255

labels_df <- tibble(label = seq(0, 9, 1),
                    item = c("Tshirt",
                             "Trousers",
                             "Pullover",
                             "Dress",
                             "Coat",
                             "Sandal",
                             "Shirt",
                             "Sneaker",
                             "Bag",
                             "AnkleBoot"))

rotate_img <- function(x){
  return(t(apply(x, 2, rev)))
}
```

In the code block above, we loaded the Fashion MNIST data, which comes already packaged into training and test sets. We then scaled the pixel densities from integer values (between 0 and 255) to floats. We created a data frame of labels for convenience, since the labels in `y_train` and `y_test` are numeric only. Finally, we wrote a function to rotate the matrix of pixel intensities so that the images will be arranged vertically when we plot them -- this is important for us humans but of no importance to the neural network we'll be training. 

Let's take a look at a few items and their labels.

```{r}
item_num <- 4
image(rotate_img(x_train[item_num, , ]))
labels_df %>%
  filter(label == y_train[item_num])
```

Okay -- I'm having a difficult time identifying these items. Can we train a sequential neural network to learn the classes?

```{r}
model <- keras_model_sequential(input_shape = c(28, 28)) %>%
  layer_flatten() %>%
  layer_dense(128, activation = "relu") %>%
  layer_dropout(0.2) %>%
  layer_dense(10)

model
```

We have a model with over 100,000 parameters! Because random weights are initially set for each of these, we can use the model straight "out of the box" for prediction. We shouldn't expect the network to perform very well though.

```{r}
predictions <- predict(model, x_train[1:2, , ])
#Predictions as a vector of log-odds
predictions
#Predictions as class-membership probabilities
tf$nn$softmax(predictions)
```

Let's define a loss function so that we can train the model by optimizing the loss.

```{r}
loss_fn <- loss_sparse_categorical_crossentropy(from_logits = TRUE)
loss_fn(y_train[1:2], predictions)
```

Before training, we'll need to set the optimizer, assign the loss function, and define the performance metric. We'll then compile the model with these attributes.

```{r}
model %>%
  compile(
    optimizer = "adam",
    loss = loss_fn,
    metrics = "accuracy"
  )
```

Note that, unlike most actions in R, the `model` object is updated here without explicitly overwriting the object. This is because the underlying process is being completed in the Python Environment and then the transformed object is being passed back to R via `reticulate`.

Since the model has been compiled, we are ready to train it. Again, we won't have to explicitly overwrite the model since the work is being done in Python and the objects passed back and forth.

```{r}
model %>% fit(x_train, 
              y_train, 
              epochs = 5)
```

Now let's evaluate our model performance.

```{r}
model %>%
  evaluate(x_test, y_test, verbose = 2)
```

We got 88% accuracy with a pretty vanilla and shallow neural network. There was only one hidden layer here, with 20% dropout. We didn't tune any model hyperparameters and only trained over 5 epochs. We can see that loss was continuing to decrease and accuracy was continuing to climb from one epoch to the next here.

Since our model has been trained, we can use it to make predictions again.

```{r}
predictions <- model %>%
  predict(x_test[1:5, , ])
tf$nn$softmax(predictions)
```

We can update our model so that it will provide class predictions rather than just the class membership probabilities.

```{r}
class_model <- keras_model_sequential() %>%
  model() %>%
  layer_activation_softmax() %>%
  layer_lambda(tf$argmax)

class_model %>%
  predict(x_test[1:5, , ])
```

Now that we've trained an assessed one neural network, go back and change your model. Add hidden layers to make it a true deep learning model. Experiment with the dropout rate or activation functions. Just remember that you'll need 10 neurons in your output layer since we have 10 classes and that the activation function used there should remain `softmax` since we are working on a multiclass classification problem. Everything else (other than the input shape) is fair game to change though!

## Summary

In this notebook we installed and used TensorFlow from R to build and assess a shallow learning network to classify clothing items from very pixelated images. The images were $28\times 28$. We saw that even a "simple" neural network was much better at predicting the class of an item based off of its pixelated image than we are as humans.